[
  {
    "objectID": "11_clean.html",
    "href": "11_clean.html",
    "title": "Clean",
    "section": "",
    "text": "To avoid pointless conflicts while working with jupyter notebooks (with different execution counts or cell metadata), it is recommended to clean the notebooks before committing anything (done automatically if you install the git hooks with nbprocess_install_git_hooks). The following functions are used to do that."
  },
  {
    "objectID": "11_clean.html#utils",
    "href": "11_clean.html#utils",
    "title": "Clean",
    "section": "Utils",
    "text": "Utils\n\n\nclean_nb\n\n clean_nb (nb, clear_all=False)\n\nClean nb from superfluous metadata\ntst = {'cell_type': 'code', 'execution_count': 26,\n       'metadata': {'hide_input': True, 'meta': 23},\n       'outputs': [{'execution_count': 2,\n                    'data': {\n                        'application/vnd.google.colaboratory.intrinsic+json': {'type': 'string'},\n                        'plain/text': ['sample output',]\n                    }, 'output': 'super'}],\n       'source': 'awesome_code'}\nnb = {'metadata': {'kernelspec': 'some_spec', 'jekyll': 'some_meta', 'meta': 37}, 'cells': [tst]}\n\nclean_nb(nb)\ntest_eq(nb['cells'][0], {'cell_type': 'code', 'execution_count': None,\n              'metadata': {'hide_input': True},\n              'outputs': [{'execution_count': None, \n                           'data': { 'plain/text': ['sample output',]},\n                           'output': 'super'}],\n              'source': 'awesome_code'})\ntest_eq(nb['metadata'], {'kernelspec': 'some_spec', 'jekyll': 'some_meta'})\n\n\n\nwrapio\n\n wrapio (strm)\n\n\n\n\nprocess_write\n\n process_write (warn_msg, proc_nb, f_in, f_out=None, disp=False)\n\n\n\n\nnbprocess_clean\n\n nbprocess_clean (fname:str=None, clear_all:bool=False, disp:bool=False,\n                  stdin:bool=False)\n\nClean all notebooks in fname to avoid merge conflicts\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nfname\nstr\nNone\nA notebook name or glob to convert\n\n\nclear_all\nbool\nFalse\nClean all metadata and outputs\n\n\ndisp\nbool\nFalse\nPrint the cleaned outputs\n\n\nstdin\nbool\nFalse\nRead input stream and not nb folder\n\n\n\nBy default (fname left to None), the all the notebooks in lib_folder are cleaned. You can opt in to fully clean the notebook by removing every bit of metadata and the cell outputs by passing clear_all=True.\n\n\n\nnbprocess_install_hooks\n\n nbprocess_install_hooks ()\n\nInstall git hooks to clean/trust notebooks automatically"
  },
  {
    "objectID": "maker.html",
    "href": "maker.html",
    "title": "maker",
    "section": "",
    "text": "These functions let us find and modify the definitions of variables in python modules.\n\n\n\n\n find_var (lines, varname)\n\nFind the line numbers where varname is defined in lines\nt = '''a_=(1,\n  2,\n  3)\n\nb_=3'''\ntest_eq(find_var(t.splitlines(), 'a_'), (0,3))\ntest_eq(find_var(t.splitlines(), 'b_'), (4,5))\n\n\n\n\n\n read_var (code, varname)\n\nEval and return the value of varname defined in code\ntest_eq(read_var(t, 'a_'), (1,2,3))\ntest_eq(read_var(t, 'b_'), 3)\n\n\n\n\n\n update_var (varname, func, fn=None, code=None)\n\nUpdate the definition of varname in file fn, by calling func with the current definition\ng = exec_new(t)\ntest_eq((g['a_'],g['b_']), ((1,2,3),3))\nt2 = update_var('a_', lambda o:0, code=t)\nexec(t2, g)\ntest_eq((g['a_'],g['b_']), (0,3))\nt3 = update_var('b_', lambda o:0, code=t)\nexec(t3, g)\ntest_eq((g['a_'],g['b_']), ((1,2,3),0))\n\n\n\n\n\n ModuleMaker (dest, name, nb_path, is_new=True, parse=True)\n\nHelper class to create exported library from notebook source cells\nIn order to export a notebook, we need an way to create a Python file. ModuleMaker fills that role. Pass in the directory where you want to module created, the name of the module, the path of the notebook source, and set is_new to True if this is a new file being created (rather than an existing file being added to). The location of the saved module will be in fname. Finally, if the source in the notebooks should not be parsed by python (such as partial class declarations in cells), parse should be set to False.\n\nNote: If doing so, then the __all__ generation will be turned off as well.\n\n\nmm = ModuleMaker(dest='tmp', name='test.testing', nb_path=Path.cwd()/'01_export.ipynb', is_new=True)\nmm.fname\n\nPath('tmp/test/testing.py')\n\n\n\n\n\n\n decor_id (d)\n\nid attr of decorator, regardless of whether called as function or bare\n\n\n\n\n\n retr_exports (trees)\n\n\n\n\n\n\n ModuleMaker.make_all (cells)\n\nCreate __all__ with all exports in cells\n\n\n\n\n\n make_code_cells (*ss)\n\n\n\n\n\n\n make_code_cell (code)\n\nWe want to add an __all__ to the top of the exported module. This methods autogenerates it from all code in cells.\nnb = make_code_cells(\"from __future__ import print_function\", \"def a():...\", \"def b():...\",\n                      \"c=d=1\", \"_f=1\", \"_g=1\", \"_all_=['_g']\", \"@patch\\ndef h(self:ca):...\")\ntest_eq(set(mm.make_all(nb)), set(['a','b','c','d', '_g']))\n\n\n\n\n\n relative_import (name, fname, level=0)\n\nConvert a module name to a name relative to fname\ntest_eq(relative_import('nbprocess.core', \"xyz\"), 'nbprocess.core')\ntest_eq(relative_import('nbprocess.core', 'nbprocess'), '.core')\n_p = Path('fastai')\ntest_eq(relative_import('fastai.core', _p/'vision'), '..core')\ntest_eq(relative_import('fastai.core', _p/'vision/transform'), '...core')\ntest_eq(relative_import('fastai.vision.transform', _p/'vision'), '.transform')\ntest_eq(relative_import('fastai.notebook.core', _p/'data'), '..notebook.core')\ntest_eq(relative_import('fastai.vision', _p/'vision'), '.')\n\n\n\n\n\n NbCell.import2relative (cell:execnb.nbio.NbCell, libname)\n\n\n\n\n\n\n update_import (source, tree, libname,\n                f=<functionrelative_importat0x7fafca4c2a70>)\n\nss = \"from nbprocess.export import *\\nfrom nbprocess.a.b import *\"\ncell = make_code_cells([ss])[0]\ncell.import2relative('nbprocess')\ntest_eq(cell.source, 'from .export import *\\nfrom .a.b import *')\n\ncell = make_code_cells([ss])[0]\ncell.import2relative('nbprocess/a')\ntest_eq(cell.source, 'from ..export import *\\nfrom .b import *')\n\n\n\n\n\n ModuleMaker.make (cells, all_cells=None, lib_name=None)\n\nWrite module containing cells with __all__ generated from all_cells\ndef _print_file(fname, mx=None): print(Path(fname).read_text().strip()[:ifnone(mx,9999)])\n\ncells = make_code_cells(\"from __future__ import print_function\", \"#|export\\ndef a(): ...\", \"def b(): ...\")\nmm.make(cells, L([cells[1]]))\nprint(Path('tmp/test/testing.py').read_text())\n\n# AUTOGENERATED! DO NOT EDIT! File to edit: ../01_export.ipynb.\n\n# %% ../01_export.ipynb 0\nfrom __future__ import print_function\n\n# %% auto 0\n__all__ = ['a']\n\n# %% ../01_export.ipynb 2\n#|export\ndef a(): ...\n\n# %% ../01_export.ipynb 3\ndef b(): ...\n\n\n\nPass all_cells=[] or parse=False if you don’t want any __all__ added.\nPassing parse=False is also handy for when writing broken up functions or classes that ast.parse might not like but still want it to be exported, such as having once cell with the contents of:\n#|export\nclass A:\nNote that by doing so we cannot properly generate a __all__, so we assume that it is unwanted.\n\nam = ModuleMaker(dest='tmp', name='test.testing_noall', nb_path=Path.cwd()/'01_export.ipynb', is_new=True, parse=False)\nam.fname\n\nPath('tmp/test/testing_noall.py')\n\n\n\ncells = make_code_cells(\"from __future__ import print_function\", \"#|export\\ndef a(): ...\", \"#|export\\nclass A:\")\nam.make(cells)\nprint(Path('tmp/test/testing_noall.py').read_text())\n\n# AUTOGENERATED! DO NOT EDIT! File to edit: ../01_export.ipynb.\n\n# %% ../01_export.ipynb 0\nfrom __future__ import print_function\n\n# %% ../01_export.ipynb 1\n#|export\ndef a(): ...\n\n# %% ../01_export.ipynb 2\n#|export\nclass A:\n\n\n\nIf is_new=False then the additional definitions are added to the bottom, and any existing __all__ is updated with the newly-added symbols.\nc2 = make_code_cells(\"def c(): ...\", \"def d(): ...\")\nmm = ModuleMaker(dest='tmp', name='test.testing', nb_path=Path.cwd()/'01_export.ipynb', is_new=False)\nmm.make(c2, c2)\n\nprint(Path('tmp/test/testing.py').read_text())\n\n# AUTOGENERATED! DO NOT EDIT! File to edit: ../01_export.ipynb.\n\n# %% ../01_export.ipynb 0\nfrom __future__ import print_function\n\n# %% auto 0\n__all__ = ['a', 'c', 'd']\n\n# %% ../01_export.ipynb 2\n#|export\ndef a(): ...\n\n# %% ../01_export.ipynb 3\ndef b(): ...\n\n# %% ../01_export.ipynb 0\ndef c(): ...\n\n# %% ../01_export.ipynb 1\ndef d(): ...\n\n\ng = exec_import('.tmp.test.testing', '*')\nfor s in \"a c d\".split(): assert s in g, s\nassert 'b' not in g\nassert g['a']() is None\n\n\n\n\n\n basic_export_nb2 (fname, name, dest=None)\n\nA basic exporter to bootstrap nbprocess using ModuleMaker\npath = Path('../nbprocess')\n(path/'read.py').unlink(missing_ok=True)\n(path/'maker.py').unlink(missing_ok=True)\n\nadd_init(path)\ncfg = get_config()\n\nbasic_export_nb2('01_read.ipynb', 'read')\nbasic_export_nb2('02_maker.ipynb', 'maker')\n\ng = exec_import('nbprocess', 'maker')\nassert g['maker'].ModuleMaker\nassert 'ModuleMaker' in g['maker'].__all__"
  },
  {
    "objectID": "test.html",
    "href": "test.html",
    "title": "Test Notebooks",
    "section": "",
    "text": "test_nb\n\n test_nb (fn, skip_flags=None, force_flags=None, do_print=False,\n          showerr=True)\n\nExecute tests in notebook in fn except those with skip_flags\ntest_nb can test a notebook, and skip over certain flags:\n\n_nb = Path('../tests/directives.ipynb')\nsuccess,duration = test_nb(_nb, skip_flags=['notest'])\nassert success\nduration\n\n0.024353981018066406\n\n\nIn that notebook the cell flagged notest raises an exception, which will be returned as a bool:\n_nb = Path('../tests/directives.ipynb')\nsuccess,duration = test_nb(_nb, showerr=False)\nassert not success\nassert not _keep_file('../tests/notest/nb_ignore.ipynb', ignore_fname='.notest') # has sibling file named .notest\nassert _keep_file('../tests/minimal.ipynb', ignore_fname='.notest') # does not have a sibling file named .notest\nSometimes you may wish to override one or more of the skip_flags, in which case you can use the argument force_flags which will remove the appropriate tag(s) from skip_flags. This is useful because skip_flags are meant to be set in the tst_flags field of settings.ini, whereas force_flags are usually passed in by the user.\n\n\n\nnbprocess_test\n\n nbprocess_test (fname:str=None, flags:str='', n_workers:int=None,\n                 timing:bool=False, do_print:str=False, pause:float=0.01,\n                 ignore_fname:str='.notest')\n\nTest in parallel the notebooks matching fname, passing along flags\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nfname\nstr\nNone\nA notebook name or glob to test\n\n\nflags\nstr\n\nSpace separated list of test flags you want to run that are normally ignored\n\n\nn_workers\nint\nNone\nNumber of workers to use\n\n\ntiming\nbool\nFalse\nTiming each notebook to see the ones are slow\n\n\ndo_print\nstr\nFalse\nPrint start and end of each NB\n\n\npause\nfloat\n0.01\nPause time (in secs) between notebooks to avoid race conditions\n\n\nignore_fname\nstr\n.notest\nfilename that will result in siblings being ignored\n\n\n\n\nnbprocess_test(n_workers=0)\n\nSuccess."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "nbprocess",
    "section": "",
    "text": "This will become v2 of nbdev in the near-ish future."
  },
  {
    "objectID": "index.html#install",
    "href": "index.html#install",
    "title": "nbprocess",
    "section": "Install",
    "text": "Install\nWith pip:\npip install nbprocess\nWith conda:\nconda install -c fastai nbprocess"
  },
  {
    "objectID": "index.html#how-to-use",
    "href": "index.html#how-to-use",
    "title": "nbprocess",
    "section": "How to use",
    "text": "How to use\nBy default docs are exported for use with Quarto. To install Quarto on Ubuntu, run nbprocess_install. See the Quarto docs for other platforms.\nYou can run nbprocess_help from the terminal to see a list of all CLI tools:\n\n!nbprocess_help\n\nnbprocess_bump_version          Increment version in `settings.py` by one\nnbprocess_clean                 Clean all notebooks in `fname` to avoid merge conflicts\nnbprocess_conda                 Create and upload a conda package.\nnbprocess_create_config         Creates a new config file for `lib_name` and `user` and saves it.\nnbprocess_deploy                Deploy docs to GitHub Pages.\nnbprocess_docs                  Generate the docs.\nnbprocess_export                Export notebooks in `path` to python modules\nnbprocess_filter                A notebook filter for quarto\nnbprocess_fix                   Create working notebook from conflicted notebook `nbname`\nnbprocess_ghp_deploy            Deploy docs in doc_path from settings.ini to GitHub Pages\nnbprocess_help                  Show help for all console scripts\nnbprocess_install               Install quarto and the current library.\nnbprocess_install_hooks         Install git hooks to clean/trust notebooks automatically\nnbprocess_install_quarto        Installs latest quarto on mac or linux.  Prints instructions for Windows.\nnbprocess_migrate_directives     Convert all directives in `fname` from v1 to v2.\nnbprocess_new                   Create a new project from the current git repo\nnbprocess_prepare               Export notebooks to python modules, test code and clean notebooks.\nnbprocess_preview               Start a local docs webserver.\nnbprocess_pypi                  Create and upload python package to pypi.\nnbprocess_quarto                Create quarto docs and README.md\nnbprocess_release               Release both conda and pypi packages.\nnbprocess_sidebar               Create sidebar.yml\nnbprocess_test                  Test in parallel the notebooks matching `fname`, passing along `flags`\nnbprocess_trust                 Trust notebooks matching `fname`\nnbprocess_update                Propagates any change in the modules matching `fname` to the notebooks that created them"
  },
  {
    "objectID": "showdoc.html",
    "href": "showdoc.html",
    "title": "showdoc",
    "section": "",
    "text": "Render nicely formatted tables that shows docments for any function or method.\ntest_eq(_maybe_nm(list), 'list')\ntest_eq(_maybe_nm('fastai'), 'fastai')\n\n\n\n\n DocmentTbl (obj, verbose=True, returns=True)\n\nCompute the docment table string\nDocmentTbl can render a markdown table showing docments if appropriate. This is an example of how a docments table will render for a function:\ndef _f(a,      # description of param a \n       b=True, # description of param b\n       c:str=None\n       ) -> int: ...\n\n_dm = DocmentTbl(_f)\n_dm\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\na\n\n\ndescription of param a\n\n\nb\nbool\nTrue\ndescription of param b\n\n\nc\nstr\nNone\n\n\n\nReturns\nint\n\n\n\n\n\nIf one column in the table has no information, for example because there are no default values, that column will not be shown. In the below example, the Default column, will not be shown. Additionally, if the return of the function is not annotated the Returns row will not be rendered:\ndef _f(a, \n        b, #param b\n        c  #param c\n       ): ...\n\n_dm2 = DocmentTbl(_f)\n_dm2\n\n\n\n\nDetails\n\n\n\n\na\n\n\n\nb\nparam b\n\n\nc\nparam c\n\n\n\nDocmentTbl also works on classes. By default, the __init__ will be rendered:\nclass _Test:\n    def __init__(self, \n                 a,      # description of param a \n                 b=True, # description of param b\n                 c:str=None):\n        ...\n        \n    def foo(self, \n            c:int,      # description of param c\n            d=True, # description of param d\n           ):\n        ...\nDocmentTbl(_Test)\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\na\n\n\ndescription of param a\n\n\nb\nbool\nTrue\ndescription of param b\n\n\nc\nstr\nNone\n\n\n\n\nYou can also pass a method to be rendered as well:\nDocmentTbl(_Test.foo)\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nc\nint\n\ndescription of param c\n\n\nd\nbool\nTrue\ndescription of param d"
  },
  {
    "objectID": "showdoc.html#show-complete-documentation-for-an-object",
    "href": "showdoc.html#show-complete-documentation-for-an-object",
    "title": "showdoc",
    "section": "Show Complete Documentation For An Object",
    "text": "Show Complete Documentation For An Object\nRender the signature as well as the docments to show complete documentation for an object.\n\n\nShowDocRenderer\n\n ShowDocRenderer (sym, disp:bool=True)\n\nShow documentation for sym\n\n\n\nBasicMarkdownRenderer\n\n BasicMarkdownRenderer (sym, disp:bool=True)\n\nShow documentation for sym\n\n\nshow_doc\n\n show_doc (sym, disp=True, renderer=None)\n\nYou can use show_doc to document apis of functions, classes or methods:\n\n\n\nf\n\n f (x:int=1)\n\nfunc docstring\n\n\n\n\n\n\nWarning\n\n\n\nIf you are using a version of python that is older than 3.10, type hints might be rendered as strings when running show_doc. We recommend upgrading to python 3.10 locally if possible so you can preview docs without this artifact. We have set the version of python to be 3.10 .github/workflows/deploy.yaml for this reason as well.\n\n\n\n\n\nf\n\n f (x:int=1)\n\nfunc docstring\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nx\nint\n1\nthe parameter x\n\n\nReturns\nNone\n\nthis function doesn’t return anything\n\n\n\n\n\n\nNumpy Docstrings\nif you have numpy docstrings instead of docments, show_doc will attempt to parse and render those just like docments:\n\n\nf\n\n f (x=1)\n\nfunc docstring in the numpy style.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nx\nint\n1\nthe parameter x\n\n\nReturns\nNone\n\nthis function doesn’t return anything\n\n\n\n\n\n\n\n\n\nWarning\n\n\n\nNumpy docstring formatting is very strict. If your docstrings do not strictly adhere to the numpy format, it will not be parsed properly and information about parameters and return values may not properly be rendered in the table below the signature. Where possible, we recommend using docments to annonate your function instead."
  },
  {
    "objectID": "showdoc.html#show_doc-on-classes",
    "href": "showdoc.html#show_doc-on-classes",
    "title": "showdoc",
    "section": "show_doc on Classes",
    "text": "show_doc on Classes\nshow_doc works on Classes, too including when you use @patch:\n\n\nFoo\n\n Foo (d:str, e:int)\n\nThis is the docstring for the init method\nYou can define methods for the class Foo with @patch which is convenient in allowing you to break up code for documentation in notebooks:\n@patch\ndef a_method(self:Foo, \n             a:list, # param a\n             b:dict,c):\n        \"This is a method\"\n        ...\n\n_res = show_doc(Foo.a_method)\n_res\n\n\nFoo.a_method\n\n Foo.a_method (a:list, b:dict, c)\n\nThis is a method\n\n\n\n\nType\nDetails\n\n\n\n\na\nlist\nparam a\n\n\nb\ndict\n\n\n\nc\n\n\n\n\n\n\n\n\n\nBasicHtmlRenderer\n\n BasicHtmlRenderer (sym, disp:bool=True)\n\nShow documentation for sym\n\n\n\nF\nF(x: int = 1)class docstring\n\n\n_res = show_doc(F.class_method)\n_res\n\n\n\nF.class_method\n\n F.class_method (foo:str, bar:int)\n\nThis is a class method.\n\n\n\n\nType\nDetails\n\n\n\n\nfoo\nstr\ndocment for parameter foo\n\n\nbar\nint\n\n\n\n\n\n\nF.regular_method\n\n F.regular_method (baz:bool=True)\n\nThis is a regular method\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nbaz\nbool\nTrue\ndocment for parameter baz\n\n\n\n\n\n\nshowdoc_nm\n\n showdoc_nm (tree)\n\nGet the fully qualified name for showdoc."
  },
  {
    "objectID": "doclinks.html",
    "href": "doclinks.html",
    "title": "doclinks",
    "section": "",
    "text": "DocLinks (mod_fn, doc_func, dest_fn, mod_name=None)\n\nCreate a module symbol index from a python source file\nThe doc index has to be stored in a file. Usually we call it _modidx.py. For testing, we’ll delete any existing file first.\ndest_fn = Path('tmp/_modidx.py')\nwith contextlib.suppress(FileNotFoundError): dest_fn.unlink()\nA link to docs is created by a doc_func. We’ll use a dummy one for testing.\ndef _help(m, s=None): return f\"help for {m}; {s}\"\nWe’re now ready to instantiate DocLinks for our test module.\n\nmod_fn = Path('tmp/everything.py')\nlink = DocLinks(mod_fn, _help, dest_fn)\nlink.mod_name\n\n'tmp.everything'\n\n\n\n\n\n\n DocLinks.write_nbprocess_idx ()\n\nCreate nbprocess documentation index file`\nInitially the index file will contain empty syms and settings:\n\ntmp_path = Path('tmp')\ntmp_path.mkdir(exist_ok=True)\nlink.write_nbprocess_idx()\nassert \"Autogenerated\" in dest_fn.read_text()\n\nprint(Path('tmp/_modidx.py').read_text())\n\n# Autogenerated by nbprocess\n\nd = {'settings': {}, 'syms': {}}\n\n\n\n\n\n\n\n get_patch_name (o)\n\ns = \"\"\"class _T: pass\n@patch\ndef _f(self:_T): pass\n@patch_to(_T)\ndef _g(self): pass\"\"\"\n\nres = [get_patch_name(o) for o in ast.parse(s).body]\ntest_eq([None, '_T._f', '_T._g'], res)\n\n\n\n\n\n DocLinks.update_syms ()\n\neverything_fn = '../tests/01_everything.ipynb'\nnb_export('../tests/00_some.thing.ipynb', 'tmp')\nnb_export(everything_fn, 'tmp')\nlink.update_syms()\nlink.write_nbprocess_idx()\ng = exec_new('import tmp._modidx')\nd = g['tmp']._modidx.d\nsymn = 'tmp.everything.a_y'\nmod_name = 'tmp.everything'\ntest_eq(d['syms'][mod_name][symn], _help(mod_name,symn))\ntest_eq(set(d['syms'][mod_name].keys()),\n        set(L('m_y', 'n_y', 'q_y', 'a_y', 'b_y', 'd_y', 'e_y', 'o_y', 'p_y', 'd_y.di_n', 'd_y.d3i_n', 'd_y.d4i_n'\n             ).map('tmp.everything.{}')))\n\n\n\n\n\n DocLinks.build_index ()\n\nlink.build_index()\ndel(sys.modules['tmp._modidx'])\ng = exec_new('import tmp._modidx')\nd = g['tmp']._modidx.d\ntest_eq(d['settings']['lib_name'], 'nbprocess')\n\n\n\n\n\n build_modidx ()\n\nCreate _modidx.py\n\n\n\n\n\n nbglob (path=None, recursive=True, symlinks=True, file_glob='*.ipynb',\n         file_re=None, folder_re=None, skip_file_glob=None,\n         skip_file_re=None, skip_folder_re='^[_.]', key='nbs_path')\n\nFind all files in a directory matching an extension given a config_key.\n\n\n\n\n\n nbprocess_export (path:str=None, recursive:bool=True, symlinks:bool=True,\n                   file_glob:str='*.ipynb', file_re:str=None,\n                   folder_re:str=None, skip_file_glob:str=None,\n                   skip_file_re:str=None, skip_folder_re:str='^[_.]')\n\nExport notebooks in path to python modules\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\npath\nstr\nNone\npath or filename\n\n\nrecursive\nbool\nTrue\nsearch subfolders\n\n\nsymlinks\nbool\nTrue\nfollow symlinks?\n\n\nfile_glob\nstr\n*.ipynb\nOnly include files matching glob\n\n\nfile_re\nstr\nNone\nOnly include files matching regex\n\n\nfolder_re\nstr\nNone\nOnly enter folders matching regex\n\n\nskip_file_glob\nstr\nNone\nSkip files matching glob\n\n\nskip_file_re\nstr\nNone\nSkip files matching regex\n\n\nskip_folder_re\nstr\n1\nSkip folders matching regex\n\n\n\n\n\n\n\n\n\n NbdevLookup (strip_libs=None, incl_libs=None, skip_mods=None)\n\nMapping from symbol names to URLs with docs\nSymbol names are taken from libraries registered using the ‘nbprocess’ entry point. By default, all libraries with this entry point are searched, but full symbol names (including module prefix) are required.\nc = NbdevLookup()\nassert c['nbprocess.doclinks.DocLinks'].startswith('http')\nassert c['numpy.array'].startswith('http')\nassert c['DocLinks'].startswith('http')\nassert not c['array']\nPass strip_libs to list libraries which should be available without requiring a module prefix.\nc = NbdevLookup(strip_libs=['nbprocess', 'nbdev_numpy'])\nassert c['array'].startswith('http')\nassert c['DocLinks'].startswith('http')\nnbprocess itself includes nbdev_lookup, an instantiated NbdevLookup with strip_libs=nbprocess.\n_nbprocess_lookup = NbdevLookup()\nassert _nbprocess_lookup['DocLinks'].startswith('http')\nassert _nbprocess_lookup['numpy.array'].startswith('http')\nassert not _nbprocess_lookup['array']"
  },
  {
    "objectID": "doclinks.html#backticks",
    "href": "doclinks.html#backticks",
    "title": "doclinks",
    "section": "Backticks",
    "text": "Backticks\n\n\nNbdevLookup.linkify\n\n NbdevLookup.linkify (md)\n\n\n\n\nNbdevLookup.link_line\n\n NbdevLookup.link_line (l)\n\nmd = \"\"\"This is a link to `numpy.array` and to `read_nb` but not a link to `foobar`.\nAnd not a link to <code>dict2nb</code>.\n\n    This is not a link to `read_nb`\nThis isn’t a link to read_nb either\n\nc = NbdevLookup('nbprocess')\nMarkdown(c.linkify(md))\nThis is a link to numpy.array and to read_nb but not a link to foobar. And not a link to dict2nb.\nThis is not a link to `read_nb`\nThis isn't a link to `read_nb` either\nPath('../nbprocess/export.py').unlink(missing_ok=True)\nnbprocess_export()\n\ng = exec_new('import nbprocess.export')\nassert hasattr(g['nbprocess'].export, 'nb_export')\nfrom nbprocess._modidx import d\nassert d['syms']['nbprocess.doclinks']['nbprocess.doclinks.DocLinks'].startswith('http')"
  },
  {
    "objectID": "sync.html",
    "href": "sync.html",
    "title": "sync",
    "section": "",
    "text": "absolute_import\n\n absolute_import (name, fname, level)\n\nUnwarps a relative import in name according to fname\ntest_eq(absolute_import('xyz', 'nbprocess', 0), 'xyz')\ntest_eq(absolute_import('', 'nbprocess', 1), 'nbprocess')\ntest_eq(absolute_import('core', 'nbprocess', 1), 'nbprocess.core')\ntest_eq(absolute_import('core', 'nbprocess/vision', 2), 'nbprocess.core')\ntest_eq(absolute_import('transform', 'nbprocess/vision', 1), 'nbprocess.vision.transform')\ntest_eq(absolute_import('notebook.core', 'nbprocess/data', 2), 'nbprocess.notebook.core')\n\n\n\nnbprocess_update\n\n nbprocess_update (fname:str)\n\nPropagates any change in the modules matching fname to the notebooks that created them\n\n\n\n\nType\nDetails\n\n\n\n\nfname\nstr\nA python file name to convert"
  },
  {
    "objectID": "migrate.html",
    "href": "migrate.html",
    "title": "Migrate to nbprocess",
    "section": "",
    "text": "migrate_nb_fm (path, overwrite=True)\n\nMigrate fastpages front matter in notebooks to a raw cell.\n\n_nb = migrate_nb_fm('../tests/2020-09-01-fastcore.ipynb', overwrite=False)\nprint(_get_raw_fm(_nb))\n\n---\ntitle: \"fastcore: An Underrated Python Library\"\ndescription: A unique python library that extends the python programming language and provides utilities that enhance productivity.\nauthor:  \"<a href='https://twitter.com/HamelHusain'>Hamel Husain</a>\"\nimage:  images/copied_from_nb/fastcore_imgs/td.png\ncategories:  [fastcore, fastai]\naliases: [/fastcore/]\n---\n\n\n\n_nb = migrate_nb_fm('../tests/2020-02-20-test.ipynb', overwrite=False)\nprint(_get_raw_fm(_nb))\n\n---\ntitle: Fastpages Notebook Blog Post\ndescription: A tutorial of fastpages for Jupyter notebooks.\nimage:  images/chart-preview.png\ncategories:  [jupyter]\naliases: [/jupyter/2020/02/20/test]\n---\n\n\n\n\n\n\n\n\n\n\n migrate_md_fm (path, overwrite=True)\n\nMake fastpages front matter in markdown files quarto compliant.\nHere is what the front matter of a markdown post looks like before:\n\nprint(run('head -n13 ../tests/2020-01-14-test-markdown-post.md'))\n\n---\ntoc: true\nlayout: post\ndescription: A minimal example of using markdown with fastpages.\ncategories: [markdown]\ntitle: An Example Markdown Post\n---\n# Example Markdown Post\n\n## Basic setup\n\nJekyll requires blog post files to be named according to the following format:\n\n\nAnd this is what it looks like after:\n\n_res = migrate_md_fm('../tests/2020-01-14-test-markdown-post.md', overwrite=False)\nprint(_res[:300])\n\n---\ntitle: An Example Markdown Post\ndescription: A minimal example of using markdown with fastpages.\ncategories: [markdown]\naliases: [/markdown/2020/01/14/test-markdown-post]\n---\n# Example Markdown Post\n\n## Basic setup\n\nJekyll requires blog post files to be named according to the following format:"
  },
  {
    "objectID": "migrate.html#convert-nbdev-v1-projects-to-nbdev-v2",
    "href": "migrate.html#convert-nbdev-v1-projects-to-nbdev-v2",
    "title": "Migrate to nbprocess",
    "section": "Convert nbdev v1 projects to nbdev v2",
    "text": "Convert nbdev v1 projects to nbdev v2\n\nMigrate Directives\n\n\nnbprocess_migrate_directives\n\n nbprocess_migrate_directives (fname:str=None, disp:bool=False,\n                               stdin:bool=False, no_skip:bool=False)\n\nConvert all directives in fname from v1 to v2.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nfname\nstr\nNone\nA notebook name or glob to convert\n\n\ndisp\nbool\nFalse\nPrint the outputs with newly formatted directives\n\n\nstdin\nbool\nFalse\nRead input stream and not nb folder\n\n\nno_skip\nbool\nFalse\nDo not skip directories beginning with an underscore"
  },
  {
    "objectID": "processors.html",
    "href": "processors.html",
    "title": "processors",
    "section": "",
    "text": "On this page we’ll be using this private helper to process a notebook and return the results, to simplify testing:\ndef _run_procs(procs=None, preprocs=None, postprocs=None, return_nb=False, path=_test_file):\n    nbp = NBProcessor(path, procs, preprocs=preprocs, postprocs=postprocs)\n    nbp.process()\n    if return_nb: return nbp.nb\n    return '\\n'.join([str(cell) for cell in nbp.nb.cells])"
  },
  {
    "objectID": "processors.html#cell-processors",
    "href": "processors.html#cell-processors",
    "title": "processors",
    "section": "Cell processors",
    "text": "Cell processors\n\n\nadd_links\n\n add_links (cell)\n\nAdd links to markdown cells\n\n\n\ncell_lang\n\n cell_lang (cell)\n\nres = _run_procs(add_links)\nassert \"[numpy.array](https://numpy.org/doc/stable/reference/generated/numpy.array.html#numpy.array)\" in res\nassert \"[ModuleMaker](https://nbprocess.fast.ai/maker#ModuleMaker) but not a link to `foobar`.\" in res\nassert \"A link in a docstring: [ModuleMaker](https://nbprocess.fast.ai/maker#ModuleMaker)\" in res\nassert \"And not a link to <code>dict2nb</code>.\" in res\nGets rid of colors that are streamed from standard out, which can interfere with static site generators:\n\n\n\nstrip_ansi\n\n strip_ansi (cell)\n\nStrip Ansi Characters.\nres = _run_procs(strip_ansi)\nassert not _re_ansi_escape.findall(res)\n\n\n\nhide_\n\n hide_ (nbp, cell)\n\nHide cell from output\nres = _run_procs(hide_)\nassert 'you will not be able to see this cell at all either' not in res\n\n\n\nhide_line\n\n hide_line (cell)\n\nHide lines of code in code cells with the directive hide_line at the end of a line of code\nres = _run_procs(hide_line)\nassert r\"def show():\\n    a = 2\\n    b = 3\" not in res\nassert r\"def show():\\n    a = 2\"                in res\n\n\n\nfilter_stream_\n\n filter_stream_ (nbp, cell, *words)\n\nRemove output lines containing any of words in cell stream output\nres = _run_procs(filter_stream_)\nexp=r\"'A line\\n', 'Another line.\\n'\"\nassert exp in res\n\n\n\nclean_magics\n\n clean_magics (cell)\n\nA preprocessor to remove cell magic commands\nres = _run_procs(clean_magics)\nassert \"%%\" not in res\n\n\n\nlang_identify\n\n lang_identify (cell)\n\nA preprocessor to identify bash/js/etc cells and mark them appropriately\nWhen we issue a shell command in a notebook with !, we need to change the code-fence from python to bash and remove the !:\nres = _run_procs(lang_identify)\nassert \"'language': 'bash'\" in res\n\n\n\nrm_header_dash\n\n rm_header_dash (cell)\n\nRemove headings that end with a dash -\nres = _run_procs(rm_header_dash)\nassert 'some words' in res\nassert 'A heading to Hide' not in res\nassert 'Yet another heading to hide' not in res\n\n\n\nrm_export\n\n rm_export (cell)\n\nRemove cells that are exported or hidden\nres = _run_procs(rm_export)\nassert 'dontshow' not in res\n\n\n\nclean_show_doc\n\n clean_show_doc (cell)\n\nRemove ShowDoc input cells\n\n\n\nexec_show_docs\n\n exec_show_docs (nb)\n\nExecute cells needed for show_docs output, including exported cells and imports\nres = _run_procs(exec_show_docs)\nassert res"
  },
  {
    "objectID": "processors.html#notebook-preprocessors",
    "href": "processors.html#notebook-preprocessors",
    "title": "processors",
    "section": "Notebook preprocessors",
    "text": "Notebook preprocessors\n\n\npopulate_language\n\n populate_language (nb)\n\nInsert cell language indicator based on notebook metadata. You should to use this before lang_identify\n\n\n\ninsert_warning\n\n insert_warning (nb)\n\nInsert Autogenerated Warning Into Notebook after the first cell.\nThis preprocessor inserts a warning in the markdown destination that the file is autogenerated. This warning is inserted in the second cell so we do not interfere with front matter.\nres = _run_procs(preprocs=[insert_warning])\nassert \"<!-- WARNING: THIS FILE WAS AUTOGENERATED!\" in res\nL('foo', None, 'a').filter(lambda x:x == 1)\n_tstre = re.compile('a')\n\n\n\nadd_show_docs\n\n add_show_docs (nb)\n\nAdd show_doc cells after exported cells, unless they are already documented\nres = _run_procs(preprocs=[populate_language, add_show_docs])\nassert \"show_doc(some_func)'\" in res\nassert \"show_doc(and_another)'\" in res\nassert \"show_doc(another_func)'\" not in res"
  },
  {
    "objectID": "processors.html#notebook-postprocessors",
    "href": "processors.html#notebook-postprocessors",
    "title": "processors",
    "section": "Notebook postprocessors",
    "text": "Notebook postprocessors\n\n\nis_frontmatter\n\n is_frontmatter (nb)\n\n_testnb = read_nb('../tests/docs_test.ipynb')\ntest_eq(_default_exp(_testnb), 'foobar')\n\n\n\nnb_fmdict\n\n nb_fmdict (nb, remove=True)\n\nInfer the front matter from a notebook’s markdown formatting\n_testnb = read_nb('../tests/docs_test.ipynb')\n_res = nb_fmdict(_testnb)\ntest_eq(_res, dict(key1=' value1', key2=' value2', categories=' [c1, c2]', title='a title', description='A description'))\n\n\n\nconstruct_fm\n\n construct_fm (fmdict:dict,\n               keys=['title','description','author','image','categories','\n               output-file','aliases'])\n\nconstruct front matter from a dictionary, but only for keys\n\n_testdict = nb_fmdict(read_nb('../tests/docs_test.ipynb'))\n_res = construct_fm(_testdict)\ntest_eq(len(_res.splitlines()), 5)\nprint(_res)\n\n---\ntitle: a title\ndescription: A description\ncategories:  [c1, c2]\n---\n\n\n\n\n\ninsert_frontmatter\n\n insert_frontmatter (nb, fm_dict:dict, filter_keys:list=['title','descript\n                     ion','author','image','categories','output-\n                     file','aliases'])\n\nAdd frontmatter into notebook based on filter_keys that exist in fmdict.\n\n\n\ninfer_frontmatter\n\n infer_frontmatter (nb)\n\nInsert front matter if it doesn’t exist automatically from nbdev styled markdown.\n_raw_res = _run_procs()\n_res = _run_procs(postprocs=infer_frontmatter)\nassert '# a title' in _raw_res and '# a title' not in _res\nassert r'description: A description\\n' in _res\nassert r'categories:  [c1, c2]\\n' in _res\nassert r'output-file: foobar\\n---' in _res"
  },
  {
    "objectID": "tutorial.html",
    "href": "tutorial.html",
    "title": "nbprocess tutorial",
    "section": "",
    "text": "nbprocess is a system for exploratory programming. In practice, programming in this way can feel very different to the kind of programming many of you will be familiar with, since we’ve mainly be taught coding techniques that are (at least implicitly) tied to the underlying tools we have access to. I’ve found that programming in a “notebook first” way can make me 2-3x more productive than I was before (when we used vscode, Visual Studio, vim, PyCharm, and similar tools).\nIn this tutorial, I’ll try to get you up and running with the basics of the nbprocess system as quickly and easily as possible. You can also watch this video in which I take you through the tutorial, step by step (to view full screen, click the little square in the bottom right of the video; to view in a separate Youtube window, click the Youtube logo):"
  },
  {
    "objectID": "tutorial.html#set-up-your-jupyter-server",
    "href": "tutorial.html#set-up-your-jupyter-server",
    "title": "nbprocess tutorial",
    "section": "Set up Your Jupyter Server",
    "text": "Set up Your Jupyter Server\n\nJupyter Environment\nTo complete this tutorial, you’ll need a Jupyter Notebook Server configured on your machine. If you have not installed Jupyter before, you may find the Anaconda Individual Edition the simplest to install.\nIf you already have experience with Jupyter, please note that everything in this tutorial must be run using the same kernel.\n\n\nInstall nbprocess\nNo matter how you installed Jupyter, you’ll need to manually install nbprocess. You can install nbprocess with pip or conda from a terminal window:\npip install nbprocess\nor\nconda install -c fastai nbprocess\nJupyter notebook has a terminal window available, so we’ll use that: 1. Start jupyter notebook 2. From the “New” dropdown on the right side, choose Terminal. 3. Enter “python -m pip install nbprocess” (or use conda as specified above)\nWhen the command completes, you’re ready to go."
  },
  {
    "objectID": "tutorial.html#set-up-repo",
    "href": "tutorial.html#set-up-repo",
    "title": "nbprocess tutorial",
    "section": "Set up Repo",
    "text": "Set up Repo\n\nCreate New Project\nTo create your new project repo, use the cli command nbprocess_new to create a new nbprocess project from an existing GitHub repo that you have cloned locally. To create a new GitHub repo locally, we recommend the gh cli tool, which allows you to create a new repo with the command gh repo create.\nAlternatively, you can create a new empty github repository using this link, and follow the instructions on github to clone the repository locally before running the command nbprocess_new\n\n\nGitHub pages\nThe nbprocess system uses quarto for documentation. You can host your site for free on Github Pages without any additional setup, so this is the approach we recommend (but it’s not required; any static site hosting will work fine).\nAfter you setup your repo and push to GitHub following the steps below, GitHub pages will automatically be built and enabled for you using continuous integration CI. We will discuss how CI works later in this tutorial, however for most people this should work by default.\n\nNOTE: Don’t expect your Pages to build & deploy properly yet; we still have some setup to do first!\n\n\nPreviewing Documents Locally\nIt is often desirable to preview the documentation locally before having it built and rendered by GitHub Pages. This requires you to run Quarto locally. You can run the command nbprocess_preview from the root of your repo to preview the documentation locally"
  },
  {
    "objectID": "tutorial.html#edit-settings.ini",
    "href": "tutorial.html#edit-settings.ini",
    "title": "nbprocess tutorial",
    "section": "Edit settings.ini",
    "text": "Edit settings.ini\nNext, edit the settings.ini file in your cloned repo. This file contains all the necessary information for when you’ll be ready to package your library. The basic structure (that can be personalized provided you change the relevant information in settings.ini) is that the root of the repo will contain your notebooks, the docs folder will contain your auto-generated docs, and a folder with a name you select will contain your auto-generated modules.\nYou’ll see these commented out lines in settings.ini. Uncomment them, and set each value as needed.\n# lib_name = your_project_name\n# repo_name = name of github repo\n# user = your_github_username\n# description = A description of your project\n# keywords = some keywords\n# author = Your Name\n# author_email = email@example.com\n# copyright = Your Name or Company Name\n# branch = The default branch of your GitHub repo (usually either master or main)\nWe’ll see some other settings we can change later."
  },
  {
    "objectID": "tutorial.html#install-git-hooks-to-avoid-and-handle-conflicts",
    "href": "tutorial.html#install-git-hooks-to-avoid-and-handle-conflicts",
    "title": "nbprocess tutorial",
    "section": "Install git hooks to avoid and handle conflicts",
    "text": "Install git hooks to avoid and handle conflicts\nJupyter Notebooks can cause challenges with git conflicts, but life becomes much easier when you use nbprocess. As a first step, run nbprocess_install_hooks in the terminal from your project folder. This will set up hooks which will remove metadata from your notebooks when you commit, greatly reducing the chance you have a conflict.\nBut if you do get a conflict later, simply run nbprocess_clean filename.ipynb. This will replace any conflicts in cell outputs with your version, and if there are conflicts in input cells, then both cells will be included in the merged file, along with standard conflict markers (e.g. =====). Then you can open the notebook in Jupyter and choose which version to keep."
  },
  {
    "objectID": "tutorial.html#start-the-documentation-server",
    "href": "tutorial.html#start-the-documentation-server",
    "title": "nbprocess tutorial",
    "section": "Start the Documentation Server",
    "text": "Start the Documentation Server\nYou can call nbprocess_preview from the root of the repo to start the documentation server so you can see how your docs will render as you edit your notebooks. This is optional, but often useful especially if you are writing docs."
  },
  {
    "objectID": "tutorial.html#edit-00_core.ipynb",
    "href": "tutorial.html#edit-00_core.ipynb",
    "title": "nbprocess tutorial",
    "section": "Edit 00_core.ipynb",
    "text": "Edit 00_core.ipynb\nNow, run jupyter notebook, and click 00_core.ipynb (you don’t have to start your notebook names with a number like we do here; but we find it helpful to show the order you’ve created your project in). You’ll see something that looks a bit like this:\n#|default_exp core\nmodule name here\n\nAPI details.\n\nLet’s explain what these special cells mean.\n\nModule name and summary\nThe markdown cell uses special syntax to define the title and summary of your module. Feel free to replace “module name here” with a title and “API details.” with a summary for your module.\n\n\nAdd a function\nLet’s add a function to this notebook, e.g.:\n#|export\ndef say_hello(to):\n    \"Say hello to somebody\"\n    return f'Hello {to}!'\nNotice how it includes #|export at the top - this means it will be included in your module, and documentation. The documentation will look like this:\n\n\nsay_hello\n\n say_hello (to)\n\nSay hello to somebody\n\n\n\nAdd examples and tests\nIt’s a good idea to give an example of your function in action. Just include regular code cells, and they’ll appear (with output) in the docs, e.g.:\nsay_hello(\"Isaac\")\nExamples can output plots, images, etc, and they’ll all appear in your docs, e.g.:\nfrom IPython.display import display,SVG\ndisplay(SVG('<svg height=\"100\"><circle cx=\"50\" cy=\"50\" r=\"40\"/></svg>'))\nYou can also include tests:\nassert say_hello(\"Hamel\")==\"Hello Hamel!\"\nYou should also add markdown headings as you create your notebook; one benefit of this is that a table of contents will be created in the documentation automatically."
  },
  {
    "objectID": "tutorial.html#edit-index.ipynb",
    "href": "tutorial.html#edit-index.ipynb",
    "title": "nbprocess tutorial",
    "section": "Edit index.ipynb",
    "text": "Edit index.ipynb\nNow you’re ready to create your documentation home page and README.md file; these are both generated automatically from index.ipynb. So click on that to open it now.\nYou’ll see that there’s already a line there to import your library - change it to use the name you selected in settings.ini. Then, add information about how to use your module, including some examples. Remember, these examples should be actual notebook code cells with real outputs."
  },
  {
    "objectID": "tutorial.html#build-lib-test",
    "href": "tutorial.html#build-lib-test",
    "title": "nbprocess tutorial",
    "section": "Build lib + test",
    "text": "Build lib + test\nNow you can create your python module. To do so, just run nbprocess_prepare from the terminal at the root of your project folder. nbprocess_prepare bundles the following commands together for you to test your code and build the library. While running nbprocess_prepare is convenient, you have the flexibility to choose these seperate pieces. - nbprocess_export: Builds the .py modules and library from the jupyter notebook - nbprocess_test: Tests all your notebooks - nbprocess_clean: Cleans your notebooks to get rid of extreanous output for Github\nSometimes you may want to ensure you have the latest version of your python library and quarto installed. You can run nbprocess_install to do an editable install of your local python library as well as fetch and install the latest version of Quarto."
  },
  {
    "objectID": "tutorial.html#preview-the-docs",
    "href": "tutorial.html#preview-the-docs",
    "title": "nbprocess tutorial",
    "section": "Preview The docs",
    "text": "Preview The docs\nIf you have not already, you should view your docs in fully rendered form to catch any mistakes. You can preview your documentation site with the command nbprocess_preview. Note that your docs will build automatically in CI (discussed below)."
  },
  {
    "objectID": "tutorial.html#commit-to-github",
    "href": "tutorial.html#commit-to-github",
    "title": "nbprocess tutorial",
    "section": "Commit to Github",
    "text": "Commit to Github\nYou can now check-in the generated files with git add, git commit and git push. (You can use git status to check which files have been generated.) The following command should be sufficient:\ngit add -A; git commit -m'check in files'; git push\nWait a minute or two for Github to process your commit, and then head over to the Github website to look at your results.\n\nContinuous Integration (CI)\nBack in your project’s Github main page, click where it says 1 commit (or 2 commits or whatever). Hopefully, you’ll see a green checkmark next to your latest commit. That means that your documentation site built correctly, and your module’s tests all passed! This is checked for you using continuous integration (CI) with GitHub actions. This does the following:\n\ncheck the notebooks have been cleaned of needless metadata to avoid merge conflicts (with nbprocess_clean)\nrun the tests in your notebooks (with nbprocess_test)\n\nThe template contains a basic CI that uses the two points above, edit the file .github/workflows/test.yaml to your liking and comment out the parts you don’t want.\nIf you have a red cross, that means something failed. Click on the cross, then click Details, and you’ll be able to see what failed.\n\nAutomatically Building Docs\nCI will automatically build docs and deploy them for you. You can see the code for this in .github/workflows/deploy.yaml, but you normally don’t have to worry about this unless you need to customize something. There might be certain circumstances in which your organization has disabled GitHub pages by default. If this is the case, you can enable Github Pages by clicking on the Settings tab in your repo, then click Pages on the left side bar. Set “Source” to gh-pages branch and the /root folder. Once you’ve saved, if you refresh that page, Github will have a link to your new website. Copy that URL, and then go back to your main repo page, click “edit” next to the description and paste the URL into the “website” section. While you’re there, go ahead and put in your project description too.\n\n\nDocs URL\nTo see the URL for your docs site, you can go to the Settings tab on your GitHub repo, click Pages on the left hand side, and your URL will be displayed there. If you need to customize the domain name, see this article.\n\n\n\nView docs and readme\nOnce everything is passing, have a look at your readme in Github. You’ll see that your index.ipynb file has been converted to a readme automatically.\nNext, go to your documentation site (e.g. by clicking on the link next to the description that you created earlier). You should see that your index notebook has also been used here.\nCongratulations, the basics are now all in place! Let’s continue and use some more advanced functionality."
  },
  {
    "objectID": "tutorial.html#add-a-class",
    "href": "tutorial.html#add-a-class",
    "title": "nbprocess tutorial",
    "section": "Add a class",
    "text": "Add a class\nCreate a class in 00_core.ipynb as follows:\n#|export\nclass HelloSayer:\n    \"Say hello to `to` using `say_hello`\"\n    def __init__(self, to): self.to = to\n        \n    def say(self):\n        \"Do the saying\"\n        return say_hello(self.to)\nThis will automatically appear in the docs like this:\n\n\nHelloSayer\n\n HelloSayer (to)\n\nSay hello to to using say_hello\n\n\nDocument with show_doc\nHowever, methods aren’t automatically documented. To add method docs, use show_doc:\nshow_doc(HelloSayer.say)\n\n\nHelloSayer.say\n\n HelloSayer.say ()\n\nDo the saying\nAnd add some examples and/or tests:\no = HelloSayer(\"Alexis\")\no.say()"
  },
  {
    "objectID": "tutorial.html#add-links-with-backticks",
    "href": "tutorial.html#add-links-with-backticks",
    "title": "nbprocess tutorial",
    "section": "Add links with backticks",
    "text": "Add links with backticks\nNotice above there is a link from our new class documentation to our function. That’s because we used backticks in the docstring:\n    \"Say hello to `to` using `say_hello`\"\nThese are automatically converted to hyperlinks wherever possible. For instance, here are hyperlinks to HelloSayer and say_hello created using backticks."
  },
  {
    "objectID": "tutorial.html#set-up-autoreload",
    "href": "tutorial.html#set-up-autoreload",
    "title": "nbprocess tutorial",
    "section": "Set up autoreload",
    "text": "Set up autoreload\nSince you’ll be often updating your modules from one notebook, and using them in another, it’s helpful if your notebook automatically reads in the new modules as soon as the python file changes. To make this happen, just add these lines to the top of your notebook:\n%load_ext autoreload\n%autoreload 2"
  },
  {
    "objectID": "tutorial.html#add-in-notebook-export-cell",
    "href": "tutorial.html#add-in-notebook-export-cell",
    "title": "nbprocess tutorial",
    "section": "Add in-notebook export cell",
    "text": "Add in-notebook export cell\nIt’s helpful to be able to export all your modules directly from a notebook, rather than going to the terminal to do it. All nbprocess commands are available directly from a notebook in Python. Add this line to any cell and run it to export your modules (I normally make this the last cell of my notebooks).\nfrom nbprocess.doclinks import nbprocess_export\nnbprocess_export()"
  },
  {
    "objectID": "tutorial.html#run-tests-in-parallel",
    "href": "tutorial.html#run-tests-in-parallel",
    "title": "nbprocess tutorial",
    "section": "Run tests in parallel",
    "text": "Run tests in parallel\nBefore you push to github or make a release, you might want to run all your tests. nbprocess can run all your notebooks in parallel to check for errors. Just run nbprocess_test in a terminal."
  },
  {
    "objectID": "tutorial.html#view-docs-locally",
    "href": "tutorial.html#view-docs-locally",
    "title": "nbprocess tutorial",
    "section": "View docs locally",
    "text": "View docs locally\nIf you want to look at your docs locally before you push to Github, you can do so by running nbprocess_preview."
  },
  {
    "objectID": "tutorial.html#set-up-prerequisites",
    "href": "tutorial.html#set-up-prerequisites",
    "title": "nbprocess tutorial",
    "section": "Set up prerequisites",
    "text": "Set up prerequisites\nIf your module requires other modules as dependencies, you can add those prerequisites to your settings.ini in the requirements section. The requirements should be separated by a space and if the module requires at least or at most a specific version of the requirement this may be specified here, too.\nFor example if your module requires the fastcore module of at least version 1.0.5, the torchvision module of at most version 0.7 and any version of matplotlib, then the prerequisites would look like this:\nrequirements = fastcore>=1.0.5 torchvision<0.7 matplotlib\nIn addition to requirements you can specify dependencies with other keywords that have different scopes. Below is a list of all possible dependency keywords:\n\nrequirements: Passed to both pip and conda setup\npip_requirements: Passed to pip setup only\nconda_requirements: Passed to conda setup only\ndev_requirements: Passed to pip setup as a development requirement\n\nFor more information about the format of dependencies, see the pypi and conda docs on creating specifications in setup.py and meta.yaml, respectively."
  },
  {
    "objectID": "tutorial.html#set-up-console-scripts",
    "href": "tutorial.html#set-up-console-scripts",
    "title": "nbprocess tutorial",
    "section": "Set up console scripts",
    "text": "Set up console scripts\nBehind the scenes, nbprocess uses that standard package setuptools for handling installation of modules. One very useful feature of setuptools is that it can automatically create cross-platform console scripts. nbprocess surfaces this functionality; to use it, use the same format as setuptools, with whitespace between each script definition (if you have more than one).\nconsole_scripts = nbprocess_export=nbprocess.cli:nbprocess_export"
  },
  {
    "objectID": "tutorial.html#test-with-editable-install",
    "href": "tutorial.html#test-with-editable-install",
    "title": "nbprocess tutorial",
    "section": "Test with editable install",
    "text": "Test with editable install\nTo test and use your modules in other projects, and use your console scripts (if you have any), the easiest approach is to use an editable install. To do this, cd to the root of your repo in the terminal, and type:\npip install -e .\n(Note that the trailing period is important.) Your module changes will be automatically picked up without reinstalling. If you add any additional console scripts, you will need to run this command again. After doing an editable install you can run nbprocess_test to run all of the tests in your notebooks."
  },
  {
    "objectID": "tutorial.html#upload-to-pypi",
    "href": "tutorial.html#upload-to-pypi",
    "title": "nbprocess tutorial",
    "section": "Upload to pypi",
    "text": "Upload to pypi\nIf you want people to be able to install your project by just typing pip install your-project then you need to upload it to pypi. The good news is, we’ve already created a fully pypi compliant installer for your project! So all you need to do is register at pypi (click “Register” on pypi) if you haven’t previously done so, and then create a file called ~/.pypirc with your login details. It should have these contents:\n[pypi]\nusername = your_pypi_username\npassword = your_pypi_password\nAnother thing you will need is twine, so you should run once\npip install twine\nTo upload your project to pypi, just type nbprocess_pypi in your project root directory. Once it’s complete, a link to your project on pypi will be printed."
  },
  {
    "objectID": "tutorial.html#upload-to-pypi-and-conda",
    "href": "tutorial.html#upload-to-pypi-and-conda",
    "title": "nbprocess tutorial",
    "section": "Upload to pypi and conda",
    "text": "Upload to pypi and conda\nThe command nbprocess_release from the root of your nbprocess repo will bump the version of your module and upload your project to both conda and pypi."
  },
  {
    "objectID": "tutorial.html#install-collapsible-headings-and-toc2",
    "href": "tutorial.html#install-collapsible-headings-and-toc2",
    "title": "nbprocess tutorial",
    "section": "Install collapsible headings and toc2",
    "text": "Install collapsible headings and toc2\nThere are two jupyter notebook extensions that I highly recommend when working with projects like this. They are:\n\nCollapsible headings: This lets you fold and unfold each section in your notebook, based on its markdown headings. You can also hit left to go to the start of a section, and right to go to the end\nTOC2: This adds a table of contents to your notebooks, which you can navigate either with the Navigate menu item it adds to your notebooks, or the TOC sidebar it adds. These can be modified and/or hidden using its settings."
  },
  {
    "objectID": "tutorial.html#math-equation-support",
    "href": "tutorial.html#math-equation-support",
    "title": "nbprocess tutorial",
    "section": "Math equation support",
    "text": "Math equation support\nnbprocess supports equations (using Quarto). You can include math in your notebook’s documentation using the following methods.\nUsing $$, e.g.:\n\n$$\\sum_{i=1}^{k+1}i$$\n\nWhich is rendered as:\n\n\\[\\sum_{i=1}^{k+1}i\\]\n\nUsing $, e.g.:\nThis version is displayed inline: $\\sum_{i=1}^{k+1}i$ . You can include text before and after.\nWhich is rendered as:\n\nThis version is displayed inline: \\(\\sum_{i=1}^{k+1}i\\) . You can include text before and after.\n\nFor more information, see the Quarto Docs"
  },
  {
    "objectID": "tutorial.html#cli-command-list",
    "href": "tutorial.html#cli-command-list",
    "title": "nbprocess tutorial",
    "section": "CLI Command List",
    "text": "CLI Command List\nYou can quickly pull up a list of all the nbprocess cli commands as well as a short description of what each command does with the command nbprocess_help."
  },
  {
    "objectID": "tutorial.html#look-at-nbprocess-source-for-more-ideas",
    "href": "tutorial.html#look-at-nbprocess-source-for-more-ideas",
    "title": "nbprocess tutorial",
    "section": "Look at nbprocess “source” for more ideas",
    "text": "Look at nbprocess “source” for more ideas\nDon’t forget that nbprocess itself is written in nbprocess! It’s a good place to look to see how fast.ai uses it in practice, and get a few tips. You’ll find the nbprocess notebooks here in the nbs folder on Github."
  },
  {
    "objectID": "process.html",
    "href": "process.html",
    "title": "process",
    "section": "",
    "text": "minimal = read_nb('../tests/minimal.ipynb')\n\n\nnb_lang\n\n nb_lang (nb)\n\n\n\n\nfirst_code_ln\n\n first_code_ln (code_list, re_pattern=None, lang='python')\n\n_tst = \"\"\" \n#|default_exp\n #|export\n#|hide_input\nfoo\n\"\"\"\ntest_eq(first_code_ln(_tst.splitlines(True)), 4)\n\n\n\nextract_directives\n\n extract_directives (cell, remove=True, lang='python')\n\nTake leading comment directives from lines of code in ss, remove #|, and split\nComment directives start with #|, followed by whitespace delimited tokens, which extract_directives extracts from the start of a cell, up until a blank line or a line containing something other than comments. The extracted lines are removed from the source.\nexp  = AttrDict(source = \"\"\"#|export module\n#|eval:false\n#| hide\n# | foo bar\n# |woo: baz\n1+2\n#bar\"\"\")\ntest_eq(extract_directives(exp), {'export':['module'], 'hide':[], 'eval:': ['false'], 'foo': ['bar'], 'woo:': ['baz']})\ntest_eq(exp.source, '#|eval: false\\n# |woo: baz\\n1+2\\n#bar')\n\n\n\nopt_set\n\n opt_set (var, newval)\n\nnewval if newval else var\n\n\n\ninstantiate\n\n instantiate (x, **kwargs)\n\nInstantiate x if it’s a type\n\n\n\nNBProcessor\n\n NBProcessor (path=None, procs=None, preprocs=None, postprocs=None,\n              nb=None, debug=False, rm_directives=True, process=False)\n\nProcess cells and nbdev comments in a notebook\nCell processors can be callables (e.g regular functions), in which case they are called for every cell:\n\neverything_fn = '../tests/01_everything.ipynb'\n\ndef print_execs(cell):\n    if 'exec' in cell.source: print(cell.source)\n\nNBProcessor(everything_fn, print_execs).process()\n\nexec(\"o_y=1\")\nexec(\"p_y=1\")\n_all_ = [o_y, 'p_y']\n\n\nComment directives are put in a cell attribute directive_ as a dictionary keyed by directive name:\n\ndef printme_func(cell):\n    if cell.directives_ and 'printme' in cell.directives_: print(cell.directives_['printme'])\n\nNBProcessor(everything_fn, printme_func).process()\n\n['testing']\n\n\nHowever, a more convenient way to handle comment directives is to use a class as a processor, and include a method in your class with the same name as your directive, surrounded by underscores:\n\nclass _PrintExample:\n    def _printme_(self, nbp, cell, to_print): print(to_print)\n\nNBProcessor(everything_fn, _PrintExample()).process()\n\ntesting\n\n\nIn the case that your processor supports just one comment directive, you can just use a regular function, with the same name as your directive, but with an underscore appended – here printme_ is identical to _PrintExample above:\n\ndef printme_(nbp, cell, to_print): print(to_print)\n\nNBProcessor(everything_fn, printme_).process()\n\ntesting\n\n\nbasic_export_nb2('01_read.ipynb', 'read')\nbasic_export_nb2('02_maker.ipynb', 'maker')\nbasic_export_nb2('03_process.ipynb', 'process')\n\ng = exec_new('import nbprocess.process')\nassert hasattr(g['nbprocess'].process, 'NBProcessor')"
  },
  {
    "objectID": "read.html#config",
    "href": "read.html#config",
    "title": "read",
    "section": "Config",
    "text": "Config\nnbprocess uses a settings.ini file in the root of the project to store all configuration details. This file is in ConfigParser format, and can be read and written conveniently using fastcore’s Config class.\n\n\nnbprocess_create_config\n\n nbprocess_create_config (user:str, lib_name:str=None,\n                          description='TODOfillmein',\n                          author='TODOfillmein',\n                          author_email='todo@example.org', path:str='.',\n                          cfg_name:str='settings.ini',\n                          branch:str='master', host:str='github', git_url:\n                          str='https://github.com/%(user)s/%(lib_name)s/tr\n                          ee/%(branch)s/', custom_sidebar:<functionbool_ar\n                          gat0x7f2c3ff00f70>=False, nbs_path:str='.',\n                          lib_path:str='%(lib_name)s',\n                          doc_path:str='_docs', tst_flags:str='',\n                          version:str='0.0.1', keywords='python',\n                          license='apache2', copyright='', status='3',\n                          min_python='3.6', audience='Developers',\n                          language='English')\n\nCreates a new config file for lib_name and user and saves it.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nuser\nstr\n\nRepo username\n\n\nlib_name\nstr\nNone\nName of library\n\n\ndescription\nstr\nTODO fill me in\nDescription for pypi\n\n\nauthor\nstr\nTODO fill me in\nAuthor for pypi\n\n\nauthor_email\nstr\ntodo@example.org\nEmail for pypi\n\n\npath\nstr\n.\nPath to create config file\n\n\ncfg_name\nstr\nsettings.ini\nName of config file to create\n\n\nbranch\nstr\nmaster\nRepo branch\n\n\nhost\nstr\ngithub\nRepo hostname\n\n\ngit_url\nstr\nhttps://github.com/%(user)s/%(lib_name)s/tree/%(branch)s/\nRepo URL\n\n\ncustom_sidebar\nbool_arg\nFalse\nCreate custom sidebar?\n\n\nnbs_path\nstr\n.\nName of folder containing notebooks\n\n\nlib_path\nstr\n%(lib_name)s\nFolder name of root module\n\n\ndoc_path\nstr\n_docs\nFolder name containing docs\n\n\ntst_flags\nstr\n\nTest flags\n\n\nversion\nstr\n0.0.1\nVersion number\n\n\nkeywords\nstr\npython\nKeywords for pypi\n\n\nlicense\nstr\napache2\nLicense for pypi\n\n\ncopyright\nstr\n\nCopyright for pypi, defaults to author from current year\n\n\nstatus\nstr\n3\nStatus for pypi\n\n\nmin_python\nstr\n3.6\nMinimum python version for pypi\n\n\naudience\nstr\nDevelopers\nAudience for pypi\n\n\nlanguage\nstr\nEnglish\nLanguage for pypi\n\n\n\nThis is a wrapper for fastcore’s save_config_file which sets some nbprocess defaults. It is also installed as a CLI command.\n\n\n\nget_config\n\n get_config (cfg_name='settings.ini', path=None)\n\nConfig for ini file found in path (defaults to cwd)\nget_config searches for settings.ini in the current directory, and then in all parent directories, stopping when it is found.\nnbprocess_create_config('fastai', path='..', nbs_path='nbs', tst_flags='tst', cfg_name='test_settings.ini')\ncfg = get_config('test_settings.ini')\ntest_eq(cfg.lib_name, 'nbprocess')\ntest_eq(cfg.git_url, \"https://github.com/fastai/nbprocess/tree/master/\")\ncwd = Path.cwd()\ntest_eq(cfg.config_path, cwd.parent.absolute())\ntest_eq(cfg.path('lib_path'), cwd.parent/'nbprocess')\ntest_eq(cfg.path('nbs_path'), cwd)\ntest_eq(cfg.path('doc_path'), cwd.parent/'_docs')\n\n\nconfig_key\n\n config_key (c, default=None, path=True, missing_ok=False)\n\nLook for key c in settings.ini and fail gracefully if not found and no default provided"
  },
  {
    "objectID": "read.html#exporting-a-basic-module",
    "href": "read.html#exporting-a-basic-module",
    "title": "read",
    "section": "Exporting a basic module",
    "text": "Exporting a basic module\n\n\nadd_init\n\n add_init (path)\n\nAdd __init__.py in all subdirs of path containing python files if it’s not there already\nPython modules require a __init.py__ file in all directories that are modules. We assume that all directories containing a python file (including in subdirectories of any depth) is a module, and therefore add a __init__.py to each.\nwith tempfile.TemporaryDirectory() as d:\n    d = Path(d)\n    (d/'a/b').mkdir(parents=True)\n    (d/'a/b/f.py').touch()\n    (d/'a/c').mkdir()\n    add_init(d)\n    assert not (d/'a/c'/_init).exists(), \"Should not add init to dir without py file\"\n    for e in [d, d/'a', d/'a/b']: assert (e/_init).exists(),f\"Missing init in {e}\"\n\n\n\nwrite_cells\n\n write_cells (cells, hdr, file, offset=0)\n\nWrite cells to file along with header hdr starting at index offset (mainly for nbprocess internal use)\n\n\n\nbasic_export_nb\n\n basic_export_nb (fname, name, dest=None)\n\nBasic exporter to bootstrap nbprocess\nThis is a simple exporter with just enough functionality to correctly export this notebook, in order to bootstrap the creation of nbprocess itself."
  },
  {
    "objectID": "shortcuts.html",
    "href": "shortcuts.html",
    "title": "shortcuts",
    "section": "",
    "text": "install ()\n\nInstall quarto and the current library.\n\n\n\n\n\n install_quarto ()\n\nInstalls latest quarto on mac or linux. Prints instructions for Windows."
  },
  {
    "objectID": "shortcuts.html#docs",
    "href": "shortcuts.html#docs",
    "title": "shortcuts",
    "section": "Docs",
    "text": "Docs\n\nGenerate Docs\n\n\ndocs\n\n docs ()\n\nGenerate the docs.\n\n\n\nPreview Docs\n\n\npreview\n\n preview ()\n\nStart a local docs webserver.\n\n\n\nDeploy Docs\n\n\ndeploy\n\n deploy ()\n\nDeploy docs to GitHub Pages."
  },
  {
    "objectID": "shortcuts.html#publish-packages",
    "href": "shortcuts.html#publish-packages",
    "title": "shortcuts",
    "section": "Publish Packages",
    "text": "Publish Packages\n\n\nrelease\n\n release ()\n\nRelease both conda and pypi packages.\n\n\n\nconda\n\n conda (ver_bump=True)\n\nCreate and upload a conda package.\n\n\n\npypi\n\n pypi (ver_bump=True)\n\nCreate and upload python package to pypi."
  },
  {
    "objectID": "shortcuts.html#other-shortcuts",
    "href": "shortcuts.html#other-shortcuts",
    "title": "shortcuts",
    "section": "Other Shortcuts",
    "text": "Other Shortcuts\n\n\nprepare\n\n prepare ()\n\nExport notebooks to python modules, test code and clean notebooks."
  },
  {
    "objectID": "shortcuts.html#help",
    "href": "shortcuts.html#help",
    "title": "shortcuts",
    "section": "Help",
    "text": "Help\nGenerate help for all console scripts\n\n\nchelp\n\n chelp ()\n\nShow help for all console scripts\n\nchelp()\n\nnbprocess_bump_version          Increment version in `settings.py` by one\nnbprocess_clean                 Clean all notebooks in `fname` to avoid merge conflicts\nnbprocess_conda                 Create and upload a conda package.\nnbprocess_create_config         Creates a new config file for `lib_name` and `user` and saves it.\nnbprocess_deploy                Deploy docs to GitHub Pages.\nnbprocess_docs                  Generate the docs.\nnbprocess_export                Export notebooks in `path` to python modules\nnbprocess_filter                A notebook filter for quarto\nnbprocess_fix                   Create working notebook from conflicted notebook `nbname`\nnbprocess_ghp_deploy            Deploy docs in doc_path from settings.ini to GitHub Pages\nnbprocess_help                  Show help for all console scripts\nnbprocess_install               Install quarto and the current library.\nnbprocess_install_hooks         Install git hooks to clean/trust notebooks automatically\nnbprocess_install_quarto        Installs latest quarto on mac or linux.  Prints instructions for Windows.\nnbprocess_migrate_directives     Convert all directives in `fname` from v1 to v2.\nnbprocess_new                   Create a new project from the current git repo\nnbprocess_prepare               Export notebooks to python modules, test code and clean notebooks.\nnbprocess_preview               Start a local docs webserver.\nnbprocess_pypi                  Create and upload python package to pypi.\nnbprocess_quarto                Create quarto docs and README.md\nnbprocess_release               Release both conda and pypi packages.\nnbprocess_sidebar               Create sidebar.yml\nnbprocess_test                  Test in parallel the notebooks matching `fname`, passing along `flags`\nnbprocess_trust                 Trust notebooks matching `fname`\nnbprocess_update                Propagates any change in the modules matching `fname` to the notebooks that created them"
  },
  {
    "objectID": "cli.html",
    "href": "cli.html",
    "title": "cli",
    "section": "",
    "text": "nbprocess_ghp_deploy\n\n nbprocess_ghp_deploy ()\n\nDeploy docs in doc_path from settings.ini to GitHub Pages\nfrom fastcore.all import *\nl = L([1,2,4])\n\n\n\nnbprocess_sidebar\n\n nbprocess_sidebar (path:str=None, symlinks:bool=False,\n                    file_glob:str=None,\n                    file_re:str='\\\\.(?:ipynb|md|html)$',\n                    folder_re:str=None, skip_file_glob:str=None,\n                    skip_file_re:str=None, skip_folder_re:str='^[_.]')\n\nCreate sidebar.yml\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\npath\nstr\nNone\npath to notebooks\n\n\nsymlinks\nbool\nFalse\nfollow symlinks?\n\n\nfile_glob\nstr\nNone\nOnly include files matching glob\n\n\nfile_re\nstr\n.(?:ipynb\nmd\n\n\nfolder_re\nstr\nNone\nOnly enter folders matching regex\n\n\nskip_file_glob\nstr\nNone\nSkip files matching glob\n\n\nskip_file_re\nstr\nNone\nSkip files matching regex\n\n\nskip_folder_re\nstr\n1\nSkip folders matching regex\n\n\n\n\n\n\nFilterDefaults\n\n FilterDefaults ()\n\nOverride FilterDefaults to change which notebook processors are used\n\n\nnbprocess_filter\n\n nbprocess_filter (nb_txt:str=None)\n\nA notebook filter for quarto\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nnb_txt\nstr\nNone\nNotebook text (uses stdin if not provided)\n\n\n\n\n\n\nnbprocess_bump_version\n\n nbprocess_bump_version (part:int=2)\n\nIncrement version in settings.py by one\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\npart\nint\n2\nPart of version to bump\n\n\n\n\n\n\nbump_version\n\n bump_version (version, part=2)\n\n\n\n\nupdate_version\n\n update_version ()\n\nAdd or update __version__ in the main __init__.py of the library\n\n\n\nextract_tgz\n\n extract_tgz (url, dest='.')\n\n\n\n\nprompt_user\n\n prompt_user (**kwargs)\n\n\n\n\nrefresh_quarto_yml\n\n refresh_quarto_yml ()\n\nGenerate _quarto.yml from settings.ini.\n\n\n\nnbprocess_new\n\n nbprocess_new ()\n\nCreate a new project from the current git repo\n\n\n\nQuarto\n\n\nnbprocess_quarto\n\n nbprocess_quarto (path:str=None, doc_path:str=None, symlinks:bool=False,\n                   file_glob:str=None,\n                   file_re:str='\\\\.(?:ipynb|md|html)$',\n                   folder_re:str=None, skip_file_glob:str=None,\n                   skip_file_re:str=None, skip_folder_re:str='^[_.]',\n                   preview:bool=False)\n\nCreate quarto docs and README.md\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\npath\nstr\nNone\npath to notebooks\n\n\ndoc_path\nstr\nNone\npath to output docs\n\n\nsymlinks\nbool\nFalse\nfollow symlinks?\n\n\nfile_glob\nstr\nNone\nOnly include files matching glob\n\n\nfile_re\nstr\n.(?:ipynb\nmd\n\n\nfolder_re\nstr\nNone\nOnly enter folders matching regex\n\n\nskip_file_glob\nstr\nNone\nSkip files matching glob\n\n\nskip_file_re\nstr\nNone\nSkip files matching regex\n\n\nskip_folder_re\nstr\n2\nSkip folders matching regex\n\n\npreview\nbool\nFalse\nPreview the site instead of building it\n\n\n\n\n\n\n\n\n\nFootnotes\n\n\n_.↩︎\n_.↩︎"
  },
  {
    "objectID": "export.html",
    "href": "export.html",
    "title": "export",
    "section": "",
    "text": "ExportModuleProc\n\n ExportModuleProc ()\n\nA processor which exports code to a module\nSpecify dest where the module(s) will be exported to, and optionally a class to use to create the module (ModuleMaker, by default).\nExported cells are stored in a dict called modules, where the keys are the modules exported to. Those without an explicit module are stored in the '#' key, which will be exported to default_exp.\neverything_fn = '../tests/01_everything.ipynb'\n\nexp = ExportModuleProc()\nproc = NBProcessor(everything_fn, exp)\nproc.process()\ntest_eq(exp.default_exp, 'everything')\nassert 'print_function'  in exp.modules['#'][0].source\nassert 'h_n' in exp.in_all['some.thing'][0].source\n\n\nblack_format\n\n black_format (cell, force=False)\n\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ncell\n\n\nA cell node\n\n\nforce\nbool\nFalse\nAn override to turn black formatting on regardless of settings.ini\n\n\n\n_cell = read_nb('../tests/black.ipynb')['cells'][0]\nblack_format(_cell, force=True)\ntest_eq(_cell.source, 'j = [1, 2, 3]')\n\n\n\ncreate_modules\n\n create_modules (path, dest, procs=None, debug=False,\n                 mod_maker=<class'nbprocess.maker.ModuleMaker'>)\n\nCreate module(s) from notebook\nLet’s check we can import a test file:\nshutil.rmtree('tmp', ignore_errors=True)\ncreate_modules('../tests/00_some.thing.ipynb', 'tmp')\n\ng = exec_new('import tmp.some.thing')\ntest_eq(g['tmp'].some.thing.__all__, ['a'])\ntest_eq(g['tmp'].some.thing.a, 1)\nWe’ll also check that our ‘everything’ file exports correctly:\ncreate_modules(everything_fn, 'tmp')\n\ng = exec_new('import tmp.everything; from tmp.everything import *')\n_alls = L(\"a b d e m n o p q\".split())\nfor s in _alls.map(\"{}_y\"): assert s in g, s\nfor s in \"c_y_nall _f_y_nall g_n h_n i_n j_n k_n l_n\".split(): assert s not in g, s\nfor s in _alls.map(\"{}_y\") + [\"c_y_nall\", \"_f_y_nall\"]: assert hasattr(g['tmp'].everything,s), s\nThat notebook should also export one extra function to tmp.some.thing:\ndel(sys.modules['tmp.some.thing']) # remove from module cache\ng = exec_new('import tmp.some.thing')\ntest_eq(g['tmp'].some.thing.__all__, ['a','h_n'])\ntest_eq(g['tmp'].some.thing.h_n(), None)\n\n\n\nnb_export\n\n nb_export (nbname, lib_path=None)\n\nPath('../nbprocess/export.py').unlink(missing_ok=True)\nnb_export('04a_export.ipynb')\n\ng = exec_new('import nbprocess.export')\nassert hasattr(g['nbprocess'].export, 'nb_export')"
  },
  {
    "objectID": "merge.html",
    "href": "merge.html",
    "title": "merge",
    "section": "",
    "text": "When working with jupyter notebooks (which are json files behind the scenes) and GitHub, it is very common that a merge conflict (that will add new lines in the notebook source file) will break some notebooks you are working on. This module defines the function fix_conflicts to fix those notebooks for you, and attempt to automatically merge standard conflicts. The remaining ones will be delimited by markdown cells like this:\n<<<<<< HEAD\n# local code here\n======\n# remote code here\n>>>>>> a7ec1b0bfb8e23b05fd0a2e6cafcb41cd0fb1c35\nBelow is an example of broken notebook. The json format is broken by the lines automatically added by git. Such a file can’t be opened in jupyter notebook.\n\nbroken = Path('../tests/example.ipynb.broken')\ntst_nb = broken.read_text()\nprint(tst_nb)\n\n{\n \"cells\": [\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": 6,\n   \"metadata\": {},\n   \"outputs\": [\n    {\n     \"data\": {\n      \"text/plain\": [\n       \"3\"\n      ]\n     },\n     \"execution_count\": 6,\n     \"metadata\": {},\n     \"output_type\": \"execute_result\"\n    }\n   ],\n   \"source\": [\n<<<<<<< HEAD\n    \"z=3\\n\",\n=======\n    \"z=2\\n\",\n>>>>>>> a7ec1b0bfb8e23b05fd0a2e6cafcb41cd0fb1c35\n    \"z\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": 7,\n   \"execution_count\": 5,\n   \"metadata\": {},\n   \"outputs\": [\n    {\n     \"data\": {\n      \"text/plain\": [\n       \"6\"\n      ]\n     },\n<<<<<<< HEAD\n     \"execution_count\": 7,\n=======\n     \"execution_count\": 5,\n>>>>>>> a7ec1b0bfb8e23b05fd0a2e6cafcb41cd0fb1c35\n     \"metadata\": {},\n     \"output_type\": \"execute_result\"\n    }\n   ],\n   \"source\": [\n    \"x=3\\n\",\n    \"y=3\\n\",\n    \"x+y\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {},\n   \"outputs\": [],\n   \"source\": []\n  }\n ],\n \"metadata\": {\n  \"kernelspec\": {\n   \"display_name\": \"Python 3\",\n   \"language\": \"python\",\n   \"name\": \"python3\"\n  }\n },\n \"nbformat\": 4,\n \"nbformat_minor\": 2\n}\n\n\n\nNote that in this example, the second conflict is easily solved: it just concerns the execution count of the second cell and can be solved by choosing either option without really impacting your notebook. This is the kind of conflict we will fix automatically. The first conflict is more complicated as it spans across two cells and there is a cell present in one version, not the other. Such a conflict (and generally the ones where the inputs of the cells change form one version to the other) aren’t automatically fixed, but we will return a proper json file where the annotations introduced by git will be placed in markdown cells."
  },
  {
    "objectID": "merge.html#creating-a-merged-notebook",
    "href": "merge.html#creating-a-merged-notebook",
    "title": "merge",
    "section": "Creating a merged notebook",
    "text": "Creating a merged notebook\nThe approach we use is to first “unpatch” the conflicted file, regenerating the two files it was originally created from. Then we redo the diff process, but using cells instead of text lines.\n\n\nunpatch\n\n unpatch (s:str)\n\nTakes a string with conflict markers and returns the two original files, and their branch names\nThe result of “unpatching” our conflicted test notebook is the two original notebooks it would have been created from. Each of these original notebooks will contain valid JSON:\n\na,b,branch1,branch2 = unpatch(tst_nb)\njson.loads(a)\n\n{'cells': [{'cell_type': 'code',\n   'execution_count': 6,\n   'metadata': {},\n   'outputs': [{'data': {'text/plain': ['3']},\n     'execution_count': 6,\n     'metadata': {},\n     'output_type': 'execute_result'}],\n   'source': ['z=3\\n', 'z']},\n  {'cell_type': 'code',\n   'execution_count': 5,\n   'metadata': {},\n   'outputs': [{'data': {'text/plain': ['6']},\n     'execution_count': 7,\n     'metadata': {},\n     'output_type': 'execute_result'}],\n   'source': ['x=3\\n', 'y=3\\n', 'x+y']},\n  {'cell_type': 'code',\n   'execution_count': None,\n   'metadata': {},\n   'outputs': [],\n   'source': []}],\n 'metadata': {'kernelspec': {'display_name': 'Python 3',\n   'language': 'python',\n   'name': 'python3'}},\n 'nbformat': 4,\n 'nbformat_minor': 2}\n\n\n\njson.loads(b)\n\n{'cells': [{'cell_type': 'code',\n   'execution_count': 6,\n   'metadata': {},\n   'outputs': [{'data': {'text/plain': ['3']},\n     'execution_count': 6,\n     'metadata': {},\n     'output_type': 'execute_result'}],\n   'source': ['z=2\\n', 'z']},\n  {'cell_type': 'code',\n   'execution_count': 5,\n   'metadata': {},\n   'outputs': [{'data': {'text/plain': ['6']},\n     'execution_count': 5,\n     'metadata': {},\n     'output_type': 'execute_result'}],\n   'source': ['x=3\\n', 'y=3\\n', 'x+y']},\n  {'cell_type': 'code',\n   'execution_count': None,\n   'metadata': {},\n   'outputs': [],\n   'source': []}],\n 'metadata': {'kernelspec': {'display_name': 'Python 3',\n   'language': 'python',\n   'name': 'python3'}},\n 'nbformat': 4,\n 'nbformat_minor': 2}\n\n\n\nbranch1,branch2\n\n('HEAD', 'a7ec1b0bfb8e23b05fd0a2e6cafcb41cd0fb1c35')\n\n\n\n\n\nnbprocess_fix\n\n nbprocess_fix (nbname:str, outname:str=None, nobackup:bool=True,\n                theirs:bool=False, noprint:bool=False)\n\nCreate working notebook from conflicted notebook nbname\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nnbname\nstr\n\nnotebook filename to fix\n\n\noutname\nstr\nNone\nfilename of output notebook, defaults to nbname\n\n\nnobackup\nbool\nTrue\ndo not backup nbname to nbname.bak if outname not provided\n\n\ntheirs\nbool\nFalse\nuse their outputs/metadata instead of ours\n\n\nnoprint\nbool\nFalse\nDo not print info about whether conflict found\n\n\n\nThis begins by optionally backing the notebook fname to fname.bak in case something goes wrong. Then it parses the broken json, solving conflicts in cells. Every conflict that only involves metadata or outputs of cells will be solved automatically by using the local (theirs==False) or the remote (theirs==True) branch. Otherwise, or for conflicts involving the inputs of cells, the json will be repaired by including the two version of the conflicted cell(s) with markdown cells indicating the conflicts. You will be able to open the notebook again and search for the conflicts (look for <<<<<<<) then fix them as you wish.\nA message will be printed indicating whether the notebook was fully merged or if conflicts remain.\n\nnbprocess_fix(broken, outname='tmp.ipynb')\nchk = read_nb('tmp.ipynb')\ntest_eq(len(chk.cells), 7)\nos.unlink('tmp.ipynb')\n\nOne or more conflict remains in the notebook, please inspect manually."
  }
]